{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d74428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d988a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e698b27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset\n",
    "data = pd.read_csv('twitter_sentiments.csv')\n",
    "# view the top rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "364f43b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25569, 3), (6393, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "train, test = train_test_split(data, test_size = 0.2, stratify = data['label'], random_state=21)\n",
    "\n",
    "# get the shape of train and test split.\n",
    "train.shape, test.shape\n",
    "## >> ((25569, 3), (6393, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8408ba81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=1000,\n",
       "                stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                      &#x27;afterwards&#x27;, &#x27;again&#x27;, &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                      &#x27;almost&#x27;, &#x27;alone&#x27;, &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                      &#x27;also&#x27;, &#x27;although&#x27;, &#x27;always&#x27;, &#x27;am&#x27;,\n",
       "                                      &#x27;among&#x27;, &#x27;amongst&#x27;, &#x27;amoungst&#x27;, &#x27;amount&#x27;,\n",
       "                                      &#x27;an&#x27;, &#x27;and&#x27;, &#x27;another&#x27;, &#x27;any&#x27;, &#x27;anyhow&#x27;,\n",
       "                                      &#x27;anyone&#x27;, &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                      &#x27;anywhere&#x27;, ...}))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000,\n",
       "                stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                      &#x27;afterwards&#x27;, &#x27;again&#x27;, &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                      &#x27;almost&#x27;, &#x27;alone&#x27;, &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                      &#x27;also&#x27;, &#x27;although&#x27;, &#x27;always&#x27;, &#x27;am&#x27;,\n",
       "                                      &#x27;among&#x27;, &#x27;amongst&#x27;, &#x27;amoungst&#x27;, &#x27;amount&#x27;,\n",
       "                                      &#x27;an&#x27;, &#x27;and&#x27;, &#x27;another&#x27;, &#x27;any&#x27;, &#x27;anyhow&#x27;,\n",
       "                                      &#x27;anyone&#x27;, &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                      &#x27;anywhere&#x27;, ...}))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=1000,\n",
       "                stop_words=frozenset({'a', 'about', 'above', 'across', 'after',\n",
       "                                      'afterwards', 'again', 'against', 'all',\n",
       "                                      'almost', 'alone', 'along', 'already',\n",
       "                                      'also', 'although', 'always', 'am',\n",
       "                                      'among', 'amongst', 'amoungst', 'amount',\n",
       "                                      'an', 'and', 'another', 'any', 'anyhow',\n",
       "                                      'anyone', 'anything', 'anyway',\n",
       "                                      'anywhere', ...}))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a TF-IDF vectorizer object\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase= True, max_features=1000, stop_words=ENGLISH_STOP_WORDS)\n",
    "\n",
    "# fit the object with the training data tweets\n",
    "tfidf_vectorizer.fit(train.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "916e6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the train and test data\n",
    "train_idf = tfidf_vectorizer.transform(train.tweet)\n",
    "test_idf  = tfidf_vectorizer.transform(test.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6fc388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45751633986928114"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the object of LinearRegression Model\n",
    "model_LR = LogisticRegression()\n",
    "\n",
    "# fit the model with the training data\n",
    "model_LR.fit(train_idf, train.label)\n",
    "\n",
    "# predict the label on the traning data\n",
    "predict_train = model_LR.predict(train_idf)\n",
    "\n",
    "# predict the model on the test data\n",
    "predict_test = model_LR.predict(test_idf)\n",
    "\n",
    "# f1 score on train data\n",
    "f1_score(y_true= train.label, y_pred= predict_train)\n",
    "## >> 0.4888178913738019\n",
    "\n",
    "f1_score(y_true= test.label, y_pred= predict_test)\n",
    "## >> 0.45751633986928114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb47f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000,\n",
       "                                 stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;,\n",
       "                                                       &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                                       &#x27;afterwards&#x27;, &#x27;again&#x27;,\n",
       "                                                       &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                                       &#x27;almost&#x27;, &#x27;alone&#x27;,\n",
       "                                                       &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                                       &#x27;also&#x27;, &#x27;although&#x27;,\n",
       "                                                       &#x27;always&#x27;, &#x27;am&#x27;, &#x27;among&#x27;,\n",
       "                                                       &#x27;amongst&#x27;, &#x27;amoungst&#x27;,\n",
       "                                                       &#x27;amount&#x27;, &#x27;an&#x27;, &#x27;and&#x27;,\n",
       "                                                       &#x27;another&#x27;, &#x27;any&#x27;,\n",
       "                                                       &#x27;anyhow&#x27;, &#x27;anyone&#x27;,\n",
       "                                                       &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                                       &#x27;anywhere&#x27;, ...}))),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000,\n",
       "                                 stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;,\n",
       "                                                       &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                                       &#x27;afterwards&#x27;, &#x27;again&#x27;,\n",
       "                                                       &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                                       &#x27;almost&#x27;, &#x27;alone&#x27;,\n",
       "                                                       &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                                       &#x27;also&#x27;, &#x27;although&#x27;,\n",
       "                                                       &#x27;always&#x27;, &#x27;am&#x27;, &#x27;among&#x27;,\n",
       "                                                       &#x27;amongst&#x27;, &#x27;amoungst&#x27;,\n",
       "                                                       &#x27;amount&#x27;, &#x27;an&#x27;, &#x27;and&#x27;,\n",
       "                                                       &#x27;another&#x27;, &#x27;any&#x27;,\n",
       "                                                       &#x27;anyhow&#x27;, &#x27;anyone&#x27;,\n",
       "                                                       &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                                       &#x27;anywhere&#x27;, ...}))),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000,\n",
       "                stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                      &#x27;afterwards&#x27;, &#x27;again&#x27;, &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                      &#x27;almost&#x27;, &#x27;alone&#x27;, &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                      &#x27;also&#x27;, &#x27;although&#x27;, &#x27;always&#x27;, &#x27;am&#x27;,\n",
       "                                      &#x27;among&#x27;, &#x27;amongst&#x27;, &#x27;amoungst&#x27;, &#x27;amount&#x27;,\n",
       "                                      &#x27;an&#x27;, &#x27;and&#x27;, &#x27;another&#x27;, &#x27;any&#x27;, &#x27;anyhow&#x27;,\n",
       "                                      &#x27;anyone&#x27;, &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                      &#x27;anywhere&#x27;, ...}))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_features=1000,\n",
       "                                 stop_words=frozenset({'a', 'about', 'above',\n",
       "                                                       'across', 'after',\n",
       "                                                       'afterwards', 'again',\n",
       "                                                       'against', 'all',\n",
       "                                                       'almost', 'alone',\n",
       "                                                       'along', 'already',\n",
       "                                                       'also', 'although',\n",
       "                                                       'always', 'am', 'among',\n",
       "                                                       'amongst', 'amoungst',\n",
       "                                                       'amount', 'an', 'and',\n",
       "                                                       'another', 'any',\n",
       "                                                       'anyhow', 'anyone',\n",
       "                                                       'anything', 'anyway',\n",
       "                                                       'anywhere', ...}))),\n",
       "                ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the stages of the pipeline\n",
    "pipeline = Pipeline(steps= [('tfidf', TfidfVectorizer(lowercase=True,\n",
    "                                                      max_features=1000,\n",
    "                                                      stop_words= ENGLISH_STOP_WORDS)),\n",
    "                            ('model', LogisticRegression())])\n",
    "\n",
    "# fit the pipeline model with the training data                            \n",
    "pipeline.fit(train.tweet, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f4cce21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample tweet\n",
    "text = [\"Virat Kohli, AB de Villiers set to auction their 'Green Day' kits from 2016 IPL match to raise funds\"]\n",
    "\n",
    "# predict the label using the pipeline\n",
    "pipeline.predict(text)\n",
    "## >> array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2011cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03bd5931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_classification.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the pipeline model\n",
    "dump(pipeline, filename=\"text_classification.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "129df75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "from joblib import load\n",
    "\n",
    "# sample tweet text\n",
    "text = [\"Virat Kohli, AB de Villiers set to auction their 'Green Day' kits from 2016 IPL match to raise funds\"]\n",
    "\n",
    "# load the saved pipleine model\n",
    "pipeline = load(\"text_classification.joblib\")\n",
    "\n",
    "# predict on the sample tweet text\n",
    "pipeline.predict(text)\n",
    "## >> array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1334d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1f14cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import tweepy\n",
    "import time\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "# api key\n",
    "api_key = \"9D6LvvCirf5d16SudvkS2SiKf\"\n",
    "# api secret key\n",
    "api_secret_key = \"5RIuJlxMfsc3drxlwibWc5qgyf2rZPPb9ZPNcTsBFDKkTEx0gf\"\n",
    "# access token\n",
    "access_token = \"1577475918192201730-nzndXCXcumuxdZfj2DkGZTrXnIxGYT\"\n",
    "# access token secret\n",
    "access_token_secret = \"bzqvlVwjcKF4h13Rwcu35aX5JvxGHVUQQ1Z65TmdNDk2G\"\n",
    "\n",
    "# authorize the API Key\n",
    "authentication = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "\n",
    "# authorization to user's access token and access token secret\n",
    "authentication.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# call the api\n",
    "api = tweepy.API(authentication, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c55f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_tweets(text_query):\n",
    "    # list to store tweets\n",
    "    tweets_list = []\n",
    "    # no of tweets\n",
    "    count = 50\n",
    "    try:\n",
    "        # Pulling individual tweets from query\n",
    "        for tweet in api.search_tweets(q=text_query, count=count):\n",
    "            print(tweet.text)\n",
    "            # Adding to list that contains all tweets\n",
    "            tweets_list.append({'created_at': tweet.created_at,\n",
    "                                'tweet_id': tweet.id,\n",
    "                                'tweet_text': tweet.text})\n",
    "        return pd.DataFrame.from_dict(tweets_list)\n",
    "\n",
    "    except BaseException as e:\n",
    "        print('failed on_status,', str(e))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f39609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_tweets import get_related_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "767e3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "from joblib import load\n",
    "\n",
    "\n",
    "# load the pipeline object\n",
    "pipeline = load(\"text_classification.joblib\")\n",
    "\n",
    "# function to get results for a particular text query\n",
    "def requestResults(name):\n",
    "    # get the tweets text\n",
    "    tweets = get_related_tweets(name)\n",
    "    # get the prediction\n",
    "    tweets['prediction'] = pipeline.predict(tweets['tweet_text'])\n",
    "    # get the value counts of different labels predicted\n",
    "    data = str(tweets.prediction.value_counts()) + '\\n\\n'\n",
    "    return data + str(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be2d5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# render default webpage\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('home.html')\n",
    "\n",
    "# when the post method detect, then redirect to success function\n",
    "@app.route('/', methods=['POST', 'GET'])\n",
    "def get_data():\n",
    "    if request.method == 'POST':\n",
    "        user = request.form['search']\n",
    "        return redirect(url_for('success', name=user))\n",
    "\n",
    "# get the data for the requested query\n",
    "@app.route('/success/<name>')\n",
    "def success(name):\n",
    "    return \"<xmp>\" + str(requestResults(name)) + \" </xmp> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c64d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [18/Dec/2022 19:45:20] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2022 19:45:20] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Dec/2022 19:45:28] \"POST / HTTP/1.1\" 302 -\n",
      "127.0.0.1 - - [18/Dec/2022 19:45:29] \"GET /success/elon%20musk HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @MattWallace888: Do you support the way Elon Musk is running Twitter?\n",
      "Elon musk, the man, is a human shitshow. What a fucking maroon. https://t.co/OmAmuiWPn5\n",
      "RT @larryelder: If Adolph Hitler, Mao Tse Tung and Elon Musk were walking down the street, and you gave an American lefty a gun with two bu‚Ä¶\n",
      "RT @MattWallace888: Elon Musk just ended Anthony Fauci‚Äôs entire career üò±\n",
      "RT @RBReich: Do I have this right‚Ä¶conservatives love free speech for Elon Musk, but hate free speech for Colin Kaepernick?\n",
      "Elon Musk seeks additional funds for Twitter\n",
      "\n",
      "https://t.co/YsHxn3JRrk\n",
      "RT @MarlowNYC: the last tweet @taylorlorenz sent before elon musk kicked her off twitter: asking for comment for a story https://t.co/DYAjl‚Ä¶\n",
      "RT @AntonioCasilli: Pendant que vous piquez une crise sur la d√©cision de Musk d'accorder un pouvoir de downvote aux \"nouveaux v√©rifi√©s\" (=c‚Ä¶\n",
      "RT @FordFischer: Elon Musk has apparently banned Washington Post‚Äôs @TaylorLorenz from the platform. https://t.co/M6f6l1txyq\n",
      "ELON MUSK if u see this tweet i want u sooo bad i want to father ur children i want to microwave u a cup of tea &amp; m‚Ä¶ https://t.co/ykp8teHDMF\n",
      "üö®‚ÄùElon Musk has just built abuse and gaslighting into an algorithm that will now determine what people see on Twitt‚Ä¶ https://t.co/uItfwbhWGi\n",
      "RT @PaoloRonk: Elon Musk non ha inventato n√® Paypal n√® Tesla\n",
      "Elon Musk fires Twitter lawyer Jim Baker, who was involved in censoring Hunter Biden laptop and Russia probe | Fox‚Ä¶ https://t.co/VQYxkpB4yX\n",
      "RT @Sven_op_1: \"Het is bizar dat iemand met een behoorlijk belangrijke positie als eigenaar van Twitter complotachtige theorie√´n aan het ve‚Ä¶\n",
      "RT @TomFitton: FBI caught abusing authority to spy on and censor Americans in @ElonMusk @Twitter Files.  Media is outraged -- at Elon Musk.\n",
      "@Muneerah_Oumarr You are highly welcome to Elon Musk Street\n",
      "RT @TomFitton: FBI caught abusing authority to spy on and censor Americans in @ElonMusk @Twitter Files.  Media is outraged -- at Elon Musk.\n",
      "RT @BscSuperAltcoin: Elon Musk Follows Rabbit King\n",
      "üê∞Rabbit King is about to take off\n",
      "üöÄLet's see 6 zeros soon\n",
      "\n",
      "Buy Today Thank Me latterüî•\n",
      "\n",
      "H‚Ä¶\n",
      "https://t.co/SHqdpbP3PY : 546ef510-76e4-4277-a85e-f9e70bbe6ad6\n",
      "* The subreddit replacing the banned ElonJet Twitter account is massively popular https://t.co/baJPRQrUMC @mashable\n",
      "RT @petervlemmix: Werkelijk niet te geloven dat politici en MSM die al jaren ongewenste meningen trachten te censureren wegens ‚Äúdesinformat‚Ä¶\n",
      "RT @Popitics1: Taylor Lorenz‚Äôs account was suspended tonight after she asked Elon Musk for comment on a story she‚Äôs working on. \n",
      "\n",
      "She hasn‚Äô‚Ä¶\n",
      "RT @nickreeves9876: 11/ Elon Musk was encouraged to buy Twitter by Peter Thiel who has said that the book which has influenced him most is‚Ä¶\n",
      "RT @CollinRugg: The FBI can‚Äôt raid Elon Musk‚Äôs home because he doesn‚Äôt have one.\n",
      "\n",
      "CHECKMATE!\n",
      "Mr Elon Musk  Tesla company are not hired on the basis of the degree, but on the skill,then we have less resources.‚Ä¶ https://t.co/kxDeJSOGBY\n",
      "RT @ChanceGardiner: Elon Musk: Una sospensione di due giorni di forse 7 account per doxxing ha ottenuto una vera pagina di Wikipedia!? Wiki‚Ä¶\n",
      "RT @davenewworld_2: Mark Cuban deconstructs Elon Musk's plan to give blue checks the power to downvote https://t.co/1elZpEvgO3\n",
      "RT @ChuckCallesto: Kari Lake Calls On Elon Musk To RELEASE ALL KATIE HOBBS TWITTER FILES and Unblock The Gateway Pundit's Twitter account..‚Ä¶\n",
      "RT @justinbaragona: Looks like the latest prominent account to be banned by Elon Musk's Twitter is Taylor Lorenz. https://t.co/BYOfFHjSnG\n",
      "Elon Musk Sounds the Alarm Over a Brewing Automobile Crisis https://t.co/RN22qAcrSl\n",
      "RT @CollinRugg: The FBI can‚Äôt raid Elon Musk‚Äôs home because he doesn‚Äôt have one.\n",
      "\n",
      "CHECKMATE!\n",
      "RT @KamVTV: CNN is threatening to leave Twitter over Elon Musk. \n",
      "\n",
      "No one will miss them.\n",
      "RT @BscGemsX1000: Elon Musk Follows Rabbit King\n",
      "üê∞Rabbit King is about to take off\n",
      "üöÄLet's see 6 zeros soon\n",
      "\n",
      "Buy Today Thank Me latterüî•\n",
      "\n",
      "Hurr‚Ä¶\n",
      "RT @elizableu: Of course the EU and UN would go after Elon Musk. It‚Äôs all so predictable.\n",
      "RT @davenewworld_2: Mark Cuban deconstructs Elon Musk's plan to give blue checks the power to downvote https://t.co/1elZpEvgO3\n",
      "@elonmusk We Android users we thank you elon musk\n",
      "RT @MattWallace888: Elon Musk just ended Anthony Fauci‚Äôs entire career üò±\n",
      "Elon Musk you are the raddest of the rad.  You are better than Santa with gift giving because yours last forever ev‚Ä¶ https://t.co/YvKQ6QixOF\n",
      "RT @Cirincione: I‚Äôm a ‚Å¶@Tesla‚Å© investor and I want ‚Å¶@elonmusk‚Å© to get off ‚Å¶@Twitter‚Å©. The value of my shares has been cut in half since he‚Ä¶\n",
      "RT @DrEricDing: Watershed moment‚ÄîSuspending @TaylorLorenz, the most legendary internet journalist today, is 100x more of an earthquake than‚Ä¶\n",
      "@ChaudharyWAD Wese ye tweet fake lg ri hai .qk Elon musk k apne account main aisi koi tweet nh\n",
      "RT @MarlowNYC: the last tweet @taylorlorenz sent before elon musk kicked her off twitter: asking for comment for a story https://t.co/DYAjl‚Ä¶\n",
      "RT @The_Beasthouse: I'll probably be banned from Twitter for this, but I've pinpointed the exact location of Elon Musk. https://t.co/TqLchO‚Ä¶\n",
      "RT @cjwerleman: Elon Musk playing footsie with Hindu supremacists who want to exterminate Muslims in India and Kashmir. https://t.co/WAioEs‚Ä¶\n",
      "RT @LaPapaEsPop: Isso √© 100% a est√©tica vaporwave, apropriada pela nova extrema-direita h√° alguns anos.\n",
      "\n",
      "https://t.co/r3GT68deoD\n",
      "RT @tucabr54: Ent√£o o FDA finalmente saiu e disse que vacinas Covid da Pfizer causam co√°gulos sangu√≠neos? Apenas 2 anos de atraso! Elon Mus‚Ä¶\n",
      "@lawrencekitema @Wadee254 Elon musk which side do you think will win?üòÖ\n",
      "RT @AnarchoTerran: Why do Alpha Males lick Elon Musk's butthole?\n",
      "RT @larryelder: If Adolph Hitler, Mao Tse Tung and Elon Musk were walking down the street, and you gave an American lefty a gun with two bu‚Ä¶\n",
      "RT @lafrancelibre31: Petit message d Elon Musk ... https://t.co/KGmL4ThELP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Dec/2022 19:45:29] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Dec/2022 19:45:59] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2022 19:46:03] \"POST / HTTP/1.1\" 302 -\n",
      "127.0.0.1 - - [18/Dec/2022 19:46:03] \"GET /success/trump HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @LarryMarcey: Isn‚Äôt it amazing how the only people that get investigated in America is Trump, his family, business associates, his suppo‚Ä¶\n",
      "@LesleyRStahl @OnPointRadio Forget the grandparenting. How about telling Trump the crap that Obama was doing was un‚Ä¶ https://t.co/9uLcVlaRLn\n",
      "@coldkappishake I can not let Trump outl1ve me\n",
      "@Brrrbon_ Wow your comparative looks great, thanks for it!  Should Trump launch in Cardano? ü§î\n",
      "RT @zsk: Taylor Lorenz seems to be the latest journalist suspended from Twitter. \n",
      "On Friday I wrote that Musk's definition of what's allowe‚Ä¶\n",
      "@oskarzwittau @RonFilipkowski Trump going to prison is in fact the fair outcome that most countries feel he deserve‚Ä¶ https://t.co/kNWqAZt4bx\n",
      "@DanFarfan @DavidSacks @elonmusk Does the fact that there is like really obvious and open evidence that Trump did c‚Ä¶ https://t.co/IhFXypvQTT\n",
      "RT @AWeissmann_: What will the House Rs do with the J6C data dump? Try to obstruct as much as possible. Don't be surprised to see them in 2‚Ä¶\n",
      "@RobertM78455424 @RWMaloneMD In December of 2018, I remember a number of prominent Democrats saying don‚Äôt take it.‚Ä¶ https://t.co/SX7IANzW7p\n",
      "RT @JuanfraEscudero: üó£Ô∏èFor sale my Donald Trump NFT. üöÄüöÄ\n",
      "\n",
      "https://t.co/og0IfHThOd\n",
      "\n",
      "Who gives more? üí∞üéÅüí∞ https://t.co/gZa7TPNGaJ\n",
      "RT @aliasvaughn: Donald Trump failed to disclose a $19.8 million loan from a company with ties to North Korea while he was president, Forbe‚Ä¶\n",
      "RT @TheUSASingers: Donald Trump had been money laundering since the 1980s in his filthy Atlantic City casinos, so it‚Äôs no surprise he‚Äôs up‚Ä¶\n",
      "@FoxNews All Trump did was show the American people the corruption in the corrupt Democrat party\n",
      "@NoLieWithBTC Gas prices are still higher than when Trump was in office.  Plus Trump was getting gas for pennies\n",
      "RT @The_Weed_Shop: üö® Trump said this month‚Äôs Twitter Files confirmed that a sinister group of Deep State bureaucrats, Silicon Valley tyrant‚Ä¶\n",
      "@StephenKing @StephenKing and the democrats, get Trump, get Trump, get Trump,  hire a bunch of incompetent bozos.‚Ä¶ https://t.co/u5UcNmLtrc\n",
      "RT @demvoice1: Mark Meadows exchanged texts w/34 GOP members on how to overturn the 2020 election.\n",
      "\n",
      "Messages included battle cries, insane‚Ä¶\n",
      "RT @DenbrotS: Plaintiffs: Pyramid scheme' promoted by Trump and Celebrity Apprentice links him to federal lawsuit\n",
      "\n",
      "Allege TFG‚Äôs ACN company‚Ä¶\n",
      "RT @2014davidharris: Democrats are using hash tags like #GOPTaxScam to push propoganda. Fricking scary stuff when you see Nancy giving her‚Ä¶\n",
      "RT @ericareport: BREAKING: Donald Trump is being investigated for breaking securities laws regarding his NFT trading cards.\n",
      "RT @imillhiser: I wrote about Matthew Kascmaryk, the Trump judge in Texas who thinks he is King of the United States.\n",
      "\n",
      "https://t.co/hpAoWBh‚Ä¶\n",
      "‚ÄúIf you are interested in balancing work and pleasure, stop trying to balance them. Instead make your work more ple‚Ä¶ https://t.co/OFCd8eu1IO\n",
      "RT @acmwallace: Donald trump lied and misled?  My god, I am shocked!\n",
      "RT @lindyli: Lauren Boebert tweeted out Speaker Pelosi‚Äôs ‚Äúassassination coordinates‚Äù for Trump‚Äôs terrorists on Jan 6\n",
      "\n",
      "Taylor Lorenz politel‚Ä¶\n",
      "RT @rhonda_harbison: @mtaibbi https://t.co/qD5x5O59y7\n",
      "New documents show top Trump officials disregarded concerns by ... https://t.co/F0LP0‚Ä¶\n",
      "RT @ericareport: BREAKING: Donald Trump is being investigated for breaking securities laws regarding his NFT trading cards.\n",
      "RT @Victorshi2020: What‚Äôs even more terrifying &amp; revolting than Trump selling digital trading cards is that they sold out in less than a da‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Dec/2022 19:47:46] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2022 19:47:49] \"POST / HTTP/1.1\" 302 -\n",
      "127.0.0.1 - - [18/Dec/2022 19:47:50] \"GET /success/trump HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@nSEnishant Agar abhi b ban hain tho Fir Duplicate modi gye te kya Donald Trump se milne k liye???? üòÑ\n",
      "@RepMTG Bogus? It's been well over a year of exhaustive investigations with a literally mountain of evidence.  Ever‚Ä¶ https://t.co/D1jFT82Amx\n",
      "RT @ChanceGardiner: Wikipedia crea la voce \"Il massacro del gioved√¨ sera\" per la sospensione momentanea di una decina di giornalisti Dem ch‚Ä¶\n",
      "@EmilioRose9 ill be collecting my winnings from the bookies, i have a bet since 2017 that trump would go to jail\n",
      "@MadScientistFF Trump\n",
      "RT @duty2warn: All 45,000 Trump cards are sold. This week Trump made 4.5 million dollars selling stolen images that aren‚Äôt NFTs but are car‚Ä¶\n",
      "RT @thehill: \"Is DeSantis about to leverage COVID vaccines against Trump and the Democrats?\" (@TheHillOpinion) https://t.co/YW7NifwSKl http‚Ä¶\n",
      "RT @JRNYcrypto: Trump NFTs up 6x since mint ü§Ø\n",
      "RT @hilarysontag: #January6thInsurrection #January6thHearing #DOJ #TrumpCoupAttempt #DonaldTrump üëá\n",
      "EVERY SINGLE GOP lawmaker who texted Mar‚Ä¶\n",
      "RT @slh061948: @SenMikeLee @SenatorBraun Another lie. It's because tRump lowered tax on the rich.\n",
      "RT @DashDobrofsky: Adam Kinzinger and Liz Cheney were both ousted for standing up against Donald Trump. Though they voted with him on a lot‚Ä¶\n",
      "I actually like Steven King, but what a jerk! -Hey! Hold the Bidens to the same standards as Trump! Trump will neve‚Ä¶ https://t.co/r5ZuRgjcKw\n",
      "RT @robreiner: Everyone can enjoy their weekend knowing that on Monday Criminal Charges against Donald Trump will be referred to the United‚Ä¶\n",
      "RT @gtconway3dg: Even Trump's NFT trading cards are based on photos that were stolen from Amazon listings and Shutterstock images. Is there‚Ä¶\n",
      "RT @TomFitton: Trump deserves a medal for this interaction.\n",
      "RT @Rasmussen_Poll: Who immediately called Trump's Jan 6th actions \"inexcusable?\"\n",
      "\n",
      "The same guy who spiked ALL FBI and DOJ efforts to inves‚Ä¶\n",
      "@ProgressiveMigi @johniadarola Soooo everything the media says about trump is a lie? Can you give examples of msnbc‚Ä¶ https://t.co/oo1eZkTVrt\n",
      "@Synchro2021 Well, Trump DID win, and we have tons of evidence to back up that claim of fact.\n",
      "* Affidavits of elect‚Ä¶ https://t.co/MK98TzV4b4\n",
      "RT @YankeeCowboy24: I love and will always honor President Trump, but I disagree with him on accepting McCarthy as House Speaker. Trump fel‚Ä¶\n",
      "RT @WalshFreedom: Saturday morning Tequila tweet: Fuck every one of my former Republican colleagues who‚Äôve known these past 7 yrs how dange‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "app.run(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
